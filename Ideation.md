"온디바이스 환경에서 멀티모달 AI의 효율적 실행을 위한 연구"라는 큰 주제 아래 3가지 세부 연구 아이디어를 논의했습니다.

## 💡 아이디어 1. 멀티모달 AI 최적화 NPU 아키텍처 설계 
“NPU 시뮬레이터를 수정하여 멀티모달 워크로드에 맞는 아키텍처를 제안하고 성능 평가”

* 연구 성격: 하드웨어 아키텍처 연구
* 연구 과제
  * GitHub에 공개된 NPU 시뮬레이터 기반으로, 멀티모달 워크로드(이미지 인코더 + 텍스트 인코더 + 디코더 등) 실행
  * 기존 멀티 DNN NPU 선행연구 검토 → 어떤 자원 스케줄링/메모리 관리 방법을 이용했는지 분석
  * 선행 연구들이 충분히 고려 못한 문제 (heterogeneous workload imbalance, 메모리 bandwidth contention, QoS 보장 등) 찾아내고, 시뮬레이터에 새로운 아키텍처 기능 추가

## 💡 아이디어 2. 상용 NPU 위에서 멀티모달 소프트웨어 스택 최적화  
“Google TPU, Apple Neural Engine, Furiosa NPU 등 실제 칩 위에서 멀티모달 워크로드 실행 후 프로파일링하여 소프트웨어 스택 최적화 방안을 모색”

* 연구 성격: 시스템 SW / 컴파일러 / 런타임 연구
* 연구 과제
  * 상용 NPU들이 제공하는 SDK, 컴파일러, 런타임 등 분석
  * 텍스트 인코더(Transformer)와 이미지 인코더(CNN/ViT)가 섞여 있을 때, 연산 패턴이 다른데 이를 효율적으로 매핑하는 방법 고안<br>
    (예를 들어, attention 연산을 NPU가 잘 처리할 수 있도록 lowering, tiling, operator fusion 같은 SW 최적화 적용) 
  * HW 구조 내부를 기업에서 상세히 공개하지 않기 때문에 내부 구조를 직접 분석하거나 수정할 수 없으니, 중간 SW 스택 레벨에서 최적화

## 💡 아이디어 3. 멀티모달 AI에 경량화 기술 적용
“멀티모달 AI 모델 자체를 pruning, quantization, distillation 등으로 경량화하여 온디비아스 칩에서 가볍게 동작할 기법 모색”

* 연구 성격: Application-level / 딥러닝 응용 연구 / 모델 레벨 최적화
* 연구 과제
  * 모델 크기 줄여서 모바일/엣지 장치에 맞게 성능 최적화
  * 멀티모달 AI의 특성에 맞는 새로운 경량화 기술을 제안
 
## 각 아이디어의 장단점 
| 아이디어 | 장점 | 단점 |
|---|---|---|
| **1. NPU 아키텍처 제안** | • “새로운 아키텍처 제안”인 만큼, 학술적으로 독창성 강조 가능<br> • 학회 논문 게재까지 노려볼 수 있음<br>  • NPU 하드웨어에 대해 깊이 있게 이해할 수 있는 좋은 기회 | • 팀원들이 NPU 하드웨어에 대한 사전 지식이 부족한 상황<br> • 이론 공부에 많은 시간을 투자해야 함<br> • 시간 관리를 잘못하면 결과가 미흡할 수 있음 |
| **2. 상용 NPU 최적화** | • 현실적이고 접근성이 높아 바로 연구실 NPU로 실험 가능<br> • NPU 하드웨어에 대한 깊은 이해가 없어도 됨 | • NPU 내부가 비공개라 깊은 아키텍처 분석과 수정에 한계가 있음<br> • 1번에 비해 연구 novelty가 약할 수 있음 |
| **3. 멀티모달 AI 경량화** | • 상대적으로 낮은 하드웨어 진입장벽<br>• 정량적 결과가 명확함 | • 이미 레드 오션이라 novelty 확보가 어려움<br> • 결과가 단순 경량화 기술 적용 수준에서 그칠 수 있음 |


## ➡️ 최종 아이디어 선정
논의 끝에 **"아이디어 1. 멀티모달 AI 최적화 NPU 아키텍처 설계"** 를 최종 주제로 선정하였습니다. 멀티모달 AI의 비효율성을 개선하고 온디바이스에서 동작할 수 있는 새로운 **NPU 하드웨어 아키텍처**를 제안합니다. 

### 선정 이유
* **도전 정신: 학문적 깊이와 문제 해결 능력 함양** <br>
하드웨어 아키텍처 관점에서 근본적인 문제를 해결하는 능력을 기를 수 있는 주제라는 것에 큰 의미를 두었습니다. 또한 하드웨어와 소프트웨어의 교차점에서 진행되는 만큼 희소성과 전문성을 확보할 수 있다고 생각합니다.

* **기술적 시의성: NPU의 중요성과 미래 가치** <br>
온디비아스 AI 환경에서 NPU는 핵심 기술이고, 특히 멀티모달 AI의 막대한 연산량을 해결할 수 있는 NPU 아키텍처는 기술적으로 매우 중요한 의미를 가질 것이라 파악했습니다. 기존 NPU의 한계를 극복하는 새로운 아키텍처를 제안함으로써, 관련 학계 및 산업계에 실질적인 기여를 할 것으로 기대합니다.

### Key words
`온디바이스 AI`, `멀티모달 AI`, `NPU 아키텍처`

###  Target Users
멀티모달 AI 모델을 온디바이스 환경에서 효율적으로 실행하고자 하는 자율주행차, 인공지능 로봇, 스마트 IoT 기기, 웨어러블 디바이스 등 다양한 산업의 **하드웨어 엔지니어**와 **AI 연구자**들을 위해 제안합니다. 이미지, 텍스트, 음성, 센서 등 여러 데이터 유형을 동시에 처리해야 하는 엔지니어와 연구자가 직면하는 전력, 메모리, 지연(latency) 제한 문제를 해결할 수 있도록 지원합니다.  

### Challenges
현재 대부분의 상용 NPU는 단일 데이터 유형(CNN 이미지 등) 처리에 최적화되어 있어, 멀티모달 워크로드를 처리할 때 Memory Bottleneck과 연산 유닛 경쟁(Contention) 문제가 발생합니다. 이로 인해 단일 NPU에서 멀티모달 데이터를 통합 처리할 경우 성능 저하, 전력 소모 증가, 실시간 반응 지연 등이 나타납니다.

본 프로젝트는 이러한 문제를 해결하고, 온디바이스 환경에서 멀티모달 AI가 저전력·저지연으로 동작할 수 있는 NPU 아키텍처를 제안하고 검증하는 것을 목표로 합니다.

### Approach
* 오픈 소스 NPU 시뮬레이터 Scale-Sim을 기반으로 기존 코드를 수정하고, 데이터 흐름 최적화, 이질적인 자원 관리, 멀티모달 융합 가속, 온칩 메모리 관리와 같은 NPU 아키텍처 요소를 포함한 모듈을 제안하여여 시뮬레이션 환경을 확장합니다.
  
* 멀티모달 AI 모델(OpenAI의 CLIP)을 이용하여, 제안한 시뮬레이터의 성능, 전력, 메모리 효율을 평가합니다.


